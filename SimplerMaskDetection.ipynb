{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data in CSV format....\n",
      "totalCut:  4072  total:  10607  totalUsed:  6535\n",
      "Label:  1\n",
      "Time passed:  35.27625894546509 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as et\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "_start_time = time.time()\n",
    "\n",
    "def tic():\n",
    "    global _start_time\n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    \n",
    "    t_time = time.time() - _start_time\n",
    "    print(\"Time passed: \", t_time, \"seconds\")\n",
    "tic()    \n",
    "dataSet = []\n",
    "parentDir = \"\"\n",
    "annotations = \"archive/annotations\"\n",
    "dataLabels = ['with_mask','without_mask','mask_weared_incorrect']\n",
    "print(\"Generating data in CSV format....\")\n",
    "\n",
    "#Used code based on the code example from the kaggle database\n",
    "for file in os.listdir(parentDir + annotations):\n",
    "    xml = et.parse(parentDir+annotations+\"/\"+file) \n",
    "    root = xml.getroot()\n",
    "    img = root[1].text\n",
    "    for i in range(4,len(root)):\n",
    "        row = []\n",
    "        row.append(img)\n",
    "        row.append(root[i][0].text)\n",
    "        for point in root[i][5]:\n",
    "            row.append(point.text)\n",
    "        dataSet.append(row)\n",
    "totalCut = 0\n",
    "totalUsed = 0\n",
    "total = 0\n",
    "smallImage = 0\n",
    "mask_weared_incorrect = 0\n",
    "LowestHeight = 30\n",
    "LowestWidth = 30\n",
    "rotationAngles = [315, 330, 0, 30, 45]\n",
    "usedImage = []\n",
    "usedLabel = []\n",
    "testImages = []\n",
    "testLabels = []\n",
    "trainImages = []\n",
    "trainLabels = []\n",
    "cropImages = []\n",
    "originalImages = []\n",
    "index = 0\n",
    "location = []\n",
    "for i in range(len(dataSet)):\n",
    "    width = int(dataSet[i][5])-int(dataSet[i][3])\n",
    "    height = int(dataSet[i][4])-int(dataSet[i][2])\n",
    "    if (LowestWidth <= width) and (LowestHeight <= height):\n",
    "        img = cv2.imread(\"archive/images/\"+dataSet[i][0])\n",
    "        originalImages.append(img)\n",
    "        crop_img = img[int(dataSet[i][3]):int(dataSet[i][5]), int(dataSet[i][2]):int(dataSet[i][4])]\n",
    "        for j in range(len(rotationAngles)):\n",
    "            scipyImage = ndimage.rotate(crop_img, rotationAngles[j])\n",
    "            cropImages.append(scipyImage)\n",
    "            location.append(index)\n",
    "            index += 1\n",
    "            resize_crop = cv2.resize(crop_img,(LowestWidth,LowestHeight))\n",
    "            usedImage.append(resize_crop)\n",
    "            for k in range(3):\n",
    "                if(dataSet[i][1] == dataLabels[k]):\n",
    "                    usedLabel.append(k)\n",
    "                    if k == 2:\n",
    "                        mask_weared_incorrect += 1;\n",
    "                    break\n",
    "            totalUsed += 1\n",
    "            total +=1\n",
    "    total += 1\n",
    "totalCut = total - totalUsed\n",
    "usedImageArray = np.array(usedImage) / 255\n",
    "usedLabelArray = np.array(usedLabel)\n",
    "locationArray = np.array(location)\n",
    "trainImages, testImages, trainLabels, testLabels, trainLocation, testLocation = train_test_split(usedImageArray, \n",
    "                                                                                                 usedLabelArray, locationArray, \n",
    "                                                                                               test_size=0.1, random_state=69)\n",
    "print(\"totalCut: \", totalCut, \" total: \",total, \" totalUsed: \", totalUsed)\n",
    "print(\"Label: \", usedLabel[0])\n",
    "tac()\n",
    "cv2.imshow(\"photo\", usedImage[0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  with_mask\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = 82\n",
    "print(\"Label: \", dataLabels[testLabels[search]])\n",
    "cv2.imshow(\"cropped\", cropImages[testLocation[search]])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data Set:  6535\n",
      "Total Test Set:  654\n",
      "Total Train Set:  5881\n",
      "Number of Masked worn Incorrect:  285\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Data Set: \", len(usedLabelArray))\n",
    "print(\"Total Test Set: \", len(testLabels))\n",
    "print(\"Total Train Set: \", len(trainLabels))\n",
    "print(\"Number of Masked worn Incorrect: \", mask_weared_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 64)        73792     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                589888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 667,459\n",
      "Trainable params: 667,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5881 samples, validate on 654 samples\n",
      "Epoch 1/10\n",
      "5881/5881 [==============================] - 15s 3ms/sample - loss: 0.2764 - accuracy: 0.8995 - val_loss: 0.1521 - val_accuracy: 0.9358\n",
      "Epoch 2/10\n",
      "5881/5881 [==============================] - 13s 2ms/sample - loss: 0.1256 - accuracy: 0.9560 - val_loss: 0.0919 - val_accuracy: 0.9664\n",
      "Epoch 3/10\n",
      "5881/5881 [==============================] - 13s 2ms/sample - loss: 0.0746 - accuracy: 0.9719 - val_loss: 0.0499 - val_accuracy: 0.9801\n",
      "Epoch 4/10\n",
      "5881/5881 [==============================] - 13s 2ms/sample - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.0161 - val_accuracy: 0.9939\n",
      "Epoch 5/10\n",
      "5881/5881 [==============================] - 13s 2ms/sample - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0401 - val_accuracy: 0.9862\n",
      "Epoch 6/10\n",
      "5881/5881 [==============================] - 13s 2ms/sample - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0038 - val_accuracy: 0.9985\n",
      "Epoch 7/10\n",
      "5881/5881 [==============================] - 14s 2ms/sample - loss: 0.0014 - accuracy: 0.9998 - val_loss: 3.7075e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "5881/5881 [==============================] - 13s 2ms/sample - loss: 3.2034e-04 - accuracy: 1.0000 - val_loss: 2.4842e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "5881/5881 [==============================] - 13s 2ms/sample - loss: 1.9586e-04 - accuracy: 1.0000 - val_loss: 1.9169e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "5881/5881 [==============================] - 13s 2ms/sample - loss: 1.5024e-04 - accuracy: 1.0000 - val_loss: 1.3922e-04 - val_accuracy: 1.0000\n",
      "654/1 - 0s - loss: 7.4747e-05 - accuracy: 1.0000\n",
      "test accuracy:  1.0\n",
      "Time passed:  133.05856204032898 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd8eb6fa2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tic()\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(LowestHeight, LowestWidth, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(3))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(trainImages, trainLabels, epochs=10, validation_data=(testImages, testLabels))\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(testImages,  testLabels, verbose=2)\n",
    "print(\"test accuracy: \", test_acc)\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "tac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remember to Delete The Three Files\n",
    "if (os.path.isfile(\"/Users/donnyhuang322/Desktop/Engineering/ECEN_and_CSCE/Senior Design/FullSystem/with_mask\")):\n",
    "    os.rmdir(\"/Users/donnyhuang322/Desktop/Engineering/ECEN_and_CSCE/Senior Design/FullSystem/with_mask\")\n",
    "if (os.path.isfile(\"/Users/donnyhuang322/Desktop/Engineering/ECEN_and_CSCE/Senior Design/FullSystem/without_mask\")):\n",
    "    os.rmdir(\"/Users/donnyhuang322/Desktop/Engineering/ECEN_and_CSCE/Senior Design/FullSystem/without_mask\")\n",
    "if (os.path.isfile(\"/Users/donnyhuang322/Desktop/Engineering/ECEN_and_CSCE/Senior Design/FullSystem/mask_weared_incorrect\")):\n",
    "    os.rmdir(\"/Users/donnyhuang322/Desktop/Engineering/ECEN_and_CSCE/Senior Design/FullSystem/mask_weared_incorrect\")    \n",
    "for i in range(3):\n",
    "    path = os.path.join(parentDir, dataLabels[i])\n",
    "    os.mkdir(path)\n",
    "\n",
    "sample = len(testLabels)\n",
    "predict = model.predict(testImages)\n",
    "percentAccuracy = []\n",
    "for i in range(sample):\n",
    "    total = 0\n",
    "    greatest = predict[i][0]\n",
    "    least = predict[i][0]\n",
    "    index = 0\n",
    "    percentage = 0\n",
    "    for j in range(3):\n",
    "        if predict[i][j] > greatest:\n",
    "            greatest = predict[i][j]\n",
    "            index = j\n",
    "        if predict[i][j] < least:\n",
    "            least = predict[i][j]\n",
    "    for j in range(3):\n",
    "        total += predict[i][j] - least\n",
    "    greatest = greatest - least\n",
    "    percentage = greatest / total * 100\n",
    "    #print(\"Percent Accuracy: \", percentage)\n",
    "    #cv2.imshow(\"photo\", cropImages[testLocation[i]])\n",
    "    cv2.imwrite(parentDir+dataLabels[index]+\"/image\"+str(i)+\".png\", cropImages[testLocation[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of test 0 :  with_mask Confidence:  68.8653679768337\n",
      "Reality:  with_mask\n",
      "\n",
      "Prediction of test 1 :  with_mask Confidence:  79.84271596992785\n",
      "Reality:  with_mask\n",
      "\n",
      "Prediction of test 2 :  without_mask Confidence:  93.75166701026481\n",
      "Reality:  without_mask\n",
      "\n",
      "Prediction of test 3 :  without_mask Confidence:  87.82165049617664\n",
      "Reality:  mask_weared_incorrect\n",
      "\n",
      "Prediction of test 4 :  mask_weared_incorrect Confidence:  64.06686894936341\n",
      "Reality:  mask_weared_incorrect\n",
      "\n",
      "Prediction of test 5 :  with_mask Confidence:  66.00118785522491\n",
      "Reality:  with_mask\n",
      "\n",
      "Prediction of test 6 :  with_mask Confidence:  83.53747187811273\n",
      "Reality:  with_mask\n",
      "\n",
      "Prediction of test 7 :  mask_weared_incorrect Confidence:  53.526969387032885\n",
      "Reality:  mask_weared_incorrect\n",
      "\n",
      "Prediction of test 8 :  with_mask Confidence:  64.28492977012232\n",
      "Reality:  with_mask\n",
      "\n",
      "Prediction of test 9 :  with_mask Confidence:  78.9467488347903\n",
      "Reality:  with_mask\n",
      "\n"
     ]
    }
   ],
   "source": [
    "specialSet = [0,0,1,2,2,0,0,2,0,0]\n",
    "specialImages = []\n",
    "specialResizes = []\n",
    "for i in range(len(specialSet)):\n",
    "    img = cv2.imread(\"testSet/test\"+str(i)+\".png\")\n",
    "    specialImages.append(img)\n",
    "    resize_crop = cv2.resize(img,(LowestWidth,LowestHeight))\n",
    "    specialResizes.append(resize_crop)\n",
    "specialArray = np.array(specialResizes) / 255\n",
    "specialPredict = model.predict(specialArray)\n",
    "for i in range(len(specialSet)):\n",
    "    total = 0\n",
    "    greatest = specialPredict[i][0]\n",
    "    least = specialPredict[i][0]\n",
    "    index = 0\n",
    "    percentage = 0\n",
    "    for j in range(3):\n",
    "        if specialPredict[i][j] > greatest:\n",
    "            greatest = specialPredict[i][j]\n",
    "            index = j\n",
    "        if specialPredict[i][j] < least:\n",
    "            least = specialPredict[i][j]\n",
    "    for j in range(3):\n",
    "        total += specialPredict[i][j] - least\n",
    "    greatest = greatest - least\n",
    "    percentage = greatest / total * 100\n",
    "    print(\"Prediction of test\",i, \": \",dataLabels[index], \"Confidence: \", percentage)\n",
    "    print(\"Reality: \", dataLabels[specialSet[i]])\n",
    "    print()\n",
    "    cv2.imshow(\"photo\", specialImages[i])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"testSet/test9.png\")\n",
    "\n",
    "blur = cv2.blur(img,(21,21))\n",
    "blurMore = cv2.blur(img,(51,51))\n",
    "cv2.imshow('my image',img)\n",
    "cv2.imshow('blur',blur)\n",
    "cv2.imshow('more blur',blurMore)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed:  5.769634962081909 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "tic()\n",
    "i = 1\n",
    "masks = 0\n",
    "maxObjectNumber = 0\n",
    "VideoFrames = parentDir + \"VideoFrames/\"\n",
    "DetectedFaces = parentDir + \"DetectedFaces/\"\n",
    "FrameNumber =\"Frame\" + str(i)\n",
    "ObjectNumberArray = []\n",
    "while os.path.exists(DetectedFaces + FrameNumber + \".txt\"):\n",
    "    f = open(DetectedFaces + FrameNumber + \".txt\", \"r\")\n",
    "    for line in f:\n",
    "        faceObject = []\n",
    "        for word in line.split():\n",
    "            faceObject.append(int(word))\n",
    "        redundant_list = []\n",
    "        img = cv2.imread(\"VideoFrames/\" + FrameNumber + \".jpg\")\n",
    "        width = faceObject[3]\n",
    "        height = faceObject[4]\n",
    "        centerx = round(faceObject[1] + width/2)\n",
    "        crop_img = img[round(faceObject[2]+height/10):round(faceObject[2]+height*2/3), round(centerx - width/4):round(centerx + width/4)]\n",
    "        resize_crop = cv2.resize(crop_img,(LowestWidth,LowestHeight))\n",
    "        #cv2.imshow(\"testImage\", resize_crop)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "        #cv2.waitKey(1)\n",
    "        redundant_list.append(resize_crop)\n",
    "        img_array = np.array(redundant_list)/255\n",
    "        array_predict = model.predict(img_array)\n",
    "        #print(\"Prediction#\" + str(i) +\": \"+ dataLabels[np.argmax(array_predict)])\n",
    "        #print(\"with mask: \" + str(array_predict[0][0])+\n",
    "        #      \"without mask: \" +str(array_predict[0][1])+\"mask_weared_incorrect: \" +str(array_predict[0][2]))\n",
    "        #cv2.imshow(\"testImage\", crop_img)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "        #cv2.waitKey(1)\n",
    "        blur = cv2.blur(crop_img, (20,20))\n",
    "        img[round(faceObject[2]+height/10):round(faceObject[2]+height*2/3), round(centerx - width/4):round(centerx + width/4)] = blur\n",
    "        if np.argmax(array_predict):\n",
    "            cv2.rectangle(img, (round(centerx - width/4),round(faceObject[2]+height/10)),(round(centerx + width/4),round(faceObject[2]+height*2/3)),(0,0,255),2)\n",
    "        else:\n",
    "            seen = 0\n",
    "            for j in range(len(ObjectNumberArray)):\n",
    "                if faceObject[0] == ObjectNumberArray[j]:\n",
    "                    seen = 1\n",
    "            if not seen:\n",
    "                ObjectNumberArray.append(faceObject[0])\n",
    "                masks += 1\n",
    "        if faceObject[0] > maxObjectNumber:\n",
    "            maxObjectNumber = faceObject[0]\n",
    "        #print(\"Frame number: \"+ FrameNumber)\n",
    "        os.remove(VideoFrames + FrameNumber + \".jpg\")\n",
    "        cv2.imwrite(VideoFrames + FrameNumber +\".jpg\",img)\n",
    "        \n",
    "    i += 1\n",
    "    FrameNumber = \"Frame\" + str(i)\n",
    "tac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed:  2.4949419498443604 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os.path\n",
    "from os import path\n",
    "tic()\n",
    "i = 1\n",
    "VideoFrames = parentDir + \"VideoFrames/\"\n",
    "FramePath = VideoFrames + \"Frame\" + str(i) + \".jpg\"\n",
    "first = cv2.imread(FramePath)\n",
    "frameSize = (first.shape[1], first.shape[0])\n",
    "#out = cv2.VideoWriter('/Users/donnyhuang322/AndroidStudioProjects/MaskEnforcerPolicyApp/app/src/main/res/raw/output_video.mp4',cv2.VideoWriter_fourcc(*'mp4v'), 16, frameSize)\n",
    "out = cv2.VideoWriter('output_video.mp4',cv2.VideoWriter_fourcc(*'mp4v'), 15, frameSize)\n",
    "\n",
    "while path.exists(FramePath):\n",
    "    video = cv2.imread(FramePath)\n",
    "    #cv2.imshow('image', img)\n",
    "    #cv2.waitKey(0)\n",
    "    resizeImage = cv2.resize(video, frameSize)\n",
    "    out.write(resizeImage)\n",
    "    i += 1\n",
    "    FramePath = VideoFrames + \"Frame\" + str(i) + \".jpg\"\n",
    "\n",
    "out.release()\n",
    "tac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "#https://dev.mysql.com/doc/connector-python/en/connector-python-example-cursor-transaction.html\n",
    "try:\n",
    "  cnx = mysql.connector.connect(user='root', password='atrocity',\n",
    "                              host='100.64.13.34',\n",
    "                              database='data')\n",
    "except mysql.connector.Error as err:\n",
    "  if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "    print(\"Something is wrong with your user name or password\")\n",
    "  elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "    print(\"Database does not exist\")\n",
    "  else:\n",
    "    print(err)\n",
    "else:\n",
    "    cursor = cnx.cursor()\n",
    "    refresh_masks = \"DELETE FROM Stats\";\n",
    "    cursor.execute(refresh_masks);\n",
    "    add_masks = (\"INSERT INTO Stats \"\n",
    "               \"(Masks, Total) \"\n",
    "               \"VALUES (%s, %s)\")\n",
    "    masks_data = (masks, maxObjectNumber)\n",
    "    cursor.execute(add_masks, masks_data)\n",
    "    cnx.commit()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
